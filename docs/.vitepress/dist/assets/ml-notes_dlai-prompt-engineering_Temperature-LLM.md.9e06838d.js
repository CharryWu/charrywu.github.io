import{_ as r,o as a,c as n,z as e,a as t}from"./chunks/framework.659f2aa6.js";const f=JSON.parse('{"title":"","description":"","frontmatter":{},"headers":[],"relativePath":"ml-notes/dlai-prompt-engineering/Temperature-LLM.md","filePath":"ml-notes/dlai-prompt-engineering/Temperature-LLM.md"}'),o={name:"ml-notes/dlai-prompt-engineering/Temperature-LLM.md"},s=e("p",null,"Temperature is the degree of randomness of model.",-1),i=e("ul",null,[e("li",null,"If temperature=0, it will always choose the same highest frequency word as next generated."),e("li",null,[t("At higher temperature, it will choose less likely words, or less frequent word as next generated."),e("br"),t(" When building models, prefer using temperature=0 for predictability & debugging"),e("br"),t(" When releasing to production, we might want to use higher temperature as higher variety of output")])],-1),l=[s,i];function d(p,m,u,c,h,g){return a(),n("div",null,l)}const w=r(o,[["render",d]]);export{f as __pageData,w as default};
